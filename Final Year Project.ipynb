{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] starting video stream...\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import os,glob\n",
    "\n",
    "num = 1\n",
    "def background_sub(c_dup,crop):\n",
    "    def trim(frame):\n",
    "        global count\n",
    "        #crop top\n",
    "        if not np.sum(frame[0]):\n",
    "            count+=1\n",
    "            return trim(frame[1:])\n",
    "        return frame\n",
    "\n",
    "    global count\n",
    "    count=0\n",
    "    gray = cv2.cvtColor(c_dup, cv2.COLOR_BGR2GRAY) \n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV +cv2.THRESH_OTSU)\n",
    "    image = trim(thresh)\n",
    "    if(count>10):\n",
    "        img_resized = crop[count-10:]\n",
    "    elif(count>5 and count<=10):\n",
    "        img_resized = crop[count-4:]\n",
    "    else:\n",
    "        img_resized = crop[:]\n",
    "    return img_resized\n",
    "\n",
    "\n",
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect, then generate a set of bounding box colors for each class\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "IGNORE = set([\"motorbike\"])\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "model = \"MobileNetSSD_deploy.caffemodel\"\n",
    "prototxt = \"MobileNetSSD_deploy.prototxt.txt\"\n",
    "conf = 0.2\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
    "\n",
    "# initialize the video stream, allow the cammera sensor to warmup,\n",
    "print(\"[INFO] starting video stream...\")\n",
    "\n",
    "vs = cv2.VideoCapture('videos/1.mp4')\n",
    "\n",
    "#time.sleep(2.0)\n",
    "\n",
    "detected_objects = []\n",
    "kill=0\n",
    "# loop over the frames from the video stream\n",
    "loop = 0\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    ret, fr = vs.read()\n",
    "    if(fr is not None):\n",
    "        frame = np.array(fr, dtype=np.uint8)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = imutils.resize(frame, width=800)\n",
    "        # grab the frame dimensions and convert it to a blob\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)),0.007843, (300, 300), 127.5)\n",
    "\n",
    "        # pass the blob through the network and obtain the detections and\n",
    "        # predictions\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        # loop over the detections\n",
    "        if(loop %12 != 0 ):\n",
    "            pass\n",
    "        else:\n",
    "            for i in np.arange(0, detections.shape[2]):\n",
    "                #print(i)\n",
    "                #break\n",
    "                # extract the confidence (i.e., probability) associated with\n",
    "                # the prediction\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                # filter out weak detections by ensuring the `confidence` is\n",
    "                # greater than the minimum confidence\n",
    "                if confidence > conf:\n",
    "                    # extract the index of the class label from the\n",
    "                    # `detections`, then compute the (x, y)-coordinates of\n",
    "                    # the bounding box for the object\n",
    "                    idx = int(detections[0, 0, i, 1])\n",
    "                    if((CLASSES[idx] not in IGNORE) or (confidence<0.30)):\n",
    "                        continue\n",
    "                    else:\n",
    "\n",
    "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                        #bike_dims = frame[startY:endY,startX:endX]\n",
    "                        cropped = frame[startY-75:endY-5,startX+30:endX-30]\n",
    "                        cropped_dup = frame[startY-75:endY-5,startX+60:endX-60]\n",
    "\n",
    "                        #cropped = frame[startY-15:endY,startX:endX]\n",
    "                        p1 = 'video_to_images/my_'+str(num)+'.png'\n",
    "                        p2 = 'video_to_images/my_'+str(num)+'_'+str(num)+'.png'\n",
    "                        #p3 = 'my_'+str(num)+'_'+'bike'+'.png'\n",
    "                        if(len(cropped_dup)!=0):\n",
    "                            try:\n",
    "                                #print(\"lengths: \",len(cropped),len(cropped_dup))\n",
    "                                img1 = Image.fromarray(cropped_dup, 'RGB')\n",
    "                                img2 = Image.fromarray(cropped, 'RGB')\n",
    "                                #img3 = Image.fromarray(bike_dims, 'RGB')\n",
    "                                img1.save(p1)\n",
    "                                img2.save(p2)\n",
    "                                #img3.save(p3)\n",
    "                                im_p1 = cv2.imread(p1)\n",
    "                                im_p2 = cv2.imread(p2)\n",
    "\n",
    "                                #cv2.waitKey(2000)\n",
    "                                num+=1\n",
    "                            except:\n",
    "                                print(\"error\")\n",
    "                            img_resized = background_sub(im_p1,im_p2)\n",
    "                            #print(img_resized)\n",
    "                            cv2.imwrite(p1,img_resized)\n",
    "                        # draw the prediction on the frame\n",
    "                        label = \"{}: {:.2f}%\".format(CLASSES[idx],confidence * 100)\n",
    "                        detected_objects.append(label)\n",
    "                        cv2.rectangle(frame, (startX, startY), (endX, endY),COLORS[idx], 2)\n",
    "                        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                        cv2.putText(frame, label, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "                        #break\n",
    "            #break\n",
    "        loop+=1\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "'''\n",
    "files = glob.glob(\"*_*_*[!bike].png\")\n",
    "print(files)\n",
    "for file in files:\n",
    "\tos.remove(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread_collection\n",
    "\n",
    "images = imread_collection('video_to_images/*.png')\n",
    "print(images)\n",
    "skip=0\n",
    "ok = []\n",
    "not_ok = []\n",
    "sub_ele = 0\n",
    "user_num = 0\n",
    "first_num = 0\n",
    "first_img = images[0]\n",
    "newpath = 'Cluster_Dataset/user_'+str(user_num)\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "cv2.imwrite(newpath+\"/\"+str(sub_ele)+'.png',cv2.cvtColor(first_img, cv2.COLOR_RGB2BGR))\n",
    "sub_ele+=1\n",
    "num=0\n",
    "ok.append(num)\n",
    "correct=0\n",
    "print(\"*****************\")\n",
    "print(\"update number(first): \",num)\n",
    "while(True):\n",
    "    num += 1\n",
    "    print(\"update number(second): \",num)\n",
    "    if(num==len(images)):\n",
    "        print(\"*******************\\n\")\n",
    "        print(\"\\n*******************\")\n",
    "        print(\"Done with 'Grouping_Images'\")\n",
    "        print(\"*******************\")\n",
    "        break\n",
    "    second_img = images[num]\n",
    "    # 1) Check if 2 images are equals\n",
    "    if first_img.shape == second_img.shape:\n",
    "        print(\"The images have same size and channels\")\n",
    "        difference = cv2.subtract(first_img, second_img)\n",
    "        b, g, r = cv2.split(difference)\n",
    "        if cv2.countNonZero(b) == 0 and cv2.countNonZero(g) == 0 and cv2.countNonZero(r) == 0:\n",
    "            print(\"The images are completely Equal\")\n",
    "        else:\n",
    "            print(\"The images are NOT equal\")\n",
    "    # 2) Check for similarities between the 2 images\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp_1, desc_1 = sift.detectAndCompute(first_img, None)\n",
    "    kp_2, desc_2 = sift.detectAndCompute(second_img, None)\n",
    "    index_params = dict(algorithm=0, trees=5)\n",
    "    search_params = dict()\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(desc_1, desc_2, k=2)\n",
    "    good_points = []\n",
    "    ratio = 0.6\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio*n.distance:\n",
    "            good_points.append(m)\n",
    "    print(\"total good_points: \",len(good_points))\n",
    "    if(len(good_points)>=10):\n",
    "        print(\"correct number: \",num)\n",
    "        cv2.imwrite(newpath+\"/\"+str(sub_ele)+'.png',cv2.cvtColor(second_img, cv2.COLOR_RGB2BGR))\n",
    "        sub_ele+=1\n",
    "        ok.append(num)\n",
    "        correct=num\n",
    "        skip+=1\n",
    "        wrong_preds = 0\n",
    "    else:\n",
    "        wrong_preds += 1 \n",
    "        skip+=1\n",
    "        if(num not in ok):\n",
    "            not_ok.append(num)\n",
    "        if(wrong_preds>1):\n",
    "            print(\"wrong preds: \",wrong_preds)\n",
    "            print(\"total skips: \",skip)\n",
    "            print(\"current number: \",num)\n",
    "            print(\"user cluster is completed\")\n",
    "            print(\"ok list: \",ok)\n",
    "            print(\"not_ok: \",not_ok)\n",
    "            print(\"*******************\")\n",
    "            sub_ele = 0\n",
    "            user_num+=1\n",
    "            first_img = images[not_ok[0]]\n",
    "            num = not_ok[0]\n",
    "            print(\"update number(first): {}\".format(num))\n",
    "            not_ok = []\n",
    "            newpath = 'Cluster_Dataset/user_'+str(user_num)\n",
    "            if not os.path.exists(newpath):\n",
    "                os.makedirs(newpath)\n",
    "            cv2.imwrite(newpath+\"/\"+str(sub_ele)+'.png',cv2.cvtColor(first_img, cv2.COLOR_RGB2BGR))\n",
    "            ok.append(num)\n",
    "            sub_ele+=1\n",
    "            skip=0\n",
    "            wrong_preds = 0\n",
    "        else:\n",
    "            print(\"user cluster is 'not at completed'\")\n",
    "    #result = cv2.drawMatches(first_img, kp_1, second_img, kp_2, good_points, None)\n",
    "\n",
    "    #cv2.imshow(\"result\", result)\n",
    "    #cv2.imshow(\"first_img\", first_img)\n",
    "    #cv2.imshow(\"Duplicate\", second_img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"Cluster_Dataset/*\")\n",
    "num=0\n",
    "for file in files:\n",
    "\t#num=0\n",
    "\tc_file = file+'/cropped/'\n",
    "\tif not os.path.exists(c_file):\n",
    "\t\tos.makedirs(c_file)\n",
    "\timages = glob.glob(file+'/*.png')\n",
    "\tfor image in images:\n",
    "\t\tnum+=1\n",
    "\t\timg = cv2.imread(image)\n",
    "\t\theight,width,channels = img.shape\n",
    "\t\th = int((height*25)/100)\n",
    "\t\tx,y = 10,1\n",
    "\t\tcrop_img = img[y:h, x:width]\n",
    "\t\t#print(c_file+str(num)+'.png')\n",
    "\t\tcv2.imwrite(c_file+str(num)+'.png',crop_img)\n",
    "\t\t#cv2.imshow(\"cropped\", crop_img)\n",
    "\t\t#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\Desktop\\Final Year Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "print(os.getcwd())\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('helmet_detection_model.hdf5')#new_4-24-1(0.10 0.96 0.23 0.93).h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,1,1,1,1,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "pis=[]\n",
    "files = glob.glob(\"Cluster_Dataset\\\\*.png\")\n",
    "print(files,len(files))\n",
    "#assert(False)\n",
    "for file in files:\n",
    "    im = image.load_img(file)\n",
    "    width,height = im.size\n",
    "    f, e = os.path.splitext(file)\n",
    "    im = im.crop((1, 1, width, height//4))\n",
    "    imResize = im.resize((160,160), Image.ANTIALIAS)\n",
    "    imResize = imResize.convert('RGB')\n",
    "    #imResize.save(f+'_1.png', 'PNG', quality=100)\n",
    "    img = image.img_to_array(imResize)\n",
    "    im_f = np.expand_dims(img,axis=0)\n",
    "    result = model.predict(im_f)\n",
    "    #print(result)\n",
    "    #print(int(result[0][0]))\n",
    "    pis.append(int(result[0][0]))\n",
    "    #print(f.split('\\\\')[-1],result[0])\n",
    "pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pis).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    print(files[i].split('\\\\')[1]+ '==> ' + str(pis[i])+'==> '+str(l1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "user_preds = []\n",
    "h1 = 0\n",
    "h2 = 0\n",
    "user_folders = glob.glob(\"Cluster_Dataset\\\\*[!.png]\")\n",
    "print(user_folders)\n",
    "for user in user_folders:\n",
    "    uname = user.split('\\\\')[-1]\n",
    "    print(uname,end=' => ')\n",
    "    cropped_files = glob.glob(user+'\\\\cropped\\\\*')\n",
    "    print('[',end='')\n",
    "    res = 'no_helmet'\n",
    "    for file in cropped_files:\n",
    "        im = image.load_img(file)\n",
    "        width,height = im.size\n",
    "        f, e = os.path.splitext(file)\n",
    "        im = im.crop((1, 1, width, height//4))\n",
    "        imResize = im.resize((82,82), Image.ANTIALIAS)\n",
    "        imResize = imResize.convert('RGB')\n",
    "        #imResize.save(f+'_1.png', 'PNG', quality=100)\n",
    "        img = image.img_to_array(imResize)\n",
    "        im_f = np.expand_dims(img,axis=0)\n",
    "        result = model.predict(im_f)\n",
    "        if(result[0][0]>=0.6):\n",
    "            res='helmet'\n",
    "        print(result[0][0],end=' ')\n",
    "    print(']',end=' => ')\n",
    "    print(res,end='\\n')\n",
    "    if(res == 'helmet'):\n",
    "        print\n",
    "        pis.append(1)\n",
    "    elif(res == 'no_helmet'):\n",
    "        pis.append(0)\n",
    "pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
